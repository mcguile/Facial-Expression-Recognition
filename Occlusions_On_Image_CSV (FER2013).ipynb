{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, ZeroPadding2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "#------------------------------\n",
    "#cpu - gpu configuration\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) \n",
    "keras.backend.set_session(sess)\n",
    "#------------------------------\n",
    "#variables\n",
    "height = 48\n",
    "width = 48\n",
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "#------------------------------\n",
    "#read kaggle facial expression recognition challenge dataset (fer2013.csv)\n",
    "#https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "\n",
    "with open(\"../images/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n",
    "\n",
    "#------------------------------\n",
    "#initialize trainset and test set\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#------------------------------\n",
    "#transfer train and test set data\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "        val = img.split(\" \")\n",
    "            \n",
    "        pixels = np.array(val, 'float32')\n",
    "        \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "    \n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\",end=\"\")\n",
    "\n",
    "#------------------------------\n",
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], width, height, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], width, height, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#store mean and std dev for later\n",
    "train_mean = np.mean(x_train)\n",
    "train_std = np.std(x_train)\n",
    "test_mean = np.mean(x_test)\n",
    "test_std = np.std(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# get coordinates of facial feature\n",
    "def get_patch(c, size):\n",
    "    top = 0 if c[1]-8 < 0 else c[1]-8\n",
    "    bot = 47 if c[1]+8 > 47 else c[1]+8\n",
    "    lef = 0 if c[0]-2 < 0 else c[0]-2\n",
    "    rig = 47 if c[0]+size-2 > 47 else c[0]+size-2\n",
    "    return top,bot,lef,rig\n",
    "\n",
    "# return image with occlusion applied \n",
    "# occlusion applied randomly over estimated position of\n",
    "# eyes or mouth if dlib cannot find landmarks\n",
    "def noisy(noise_typ,image,d):\n",
    "    \n",
    "    if not d:\n",
    "        d = {\"mouth\": np.array([16,38]), \"both\": np.array([11,18])}\n",
    "        \n",
    "    feature = random.choice([0,1])\n",
    "    if feature == 0:\n",
    "        top,bot,lef,rig = get_patch(d[\"both\"],30)\n",
    "    elif feature == 1:\n",
    "        top,bot,lef,rig = get_patch(d[\"mouth\"],25)\n",
    "    modded = image.copy()\n",
    "    row,col,ch = modded.shape\n",
    "    if noise_typ == \"s&p\":\n",
    "        noise = skimage.util.random_noise(modded,mode=noise_typ, amount = 1)\n",
    "    else:\n",
    "        noise = skimage.util.random_noise(modded,mode=noise_typ)\n",
    "    modded[top:bot,lef:rig] = img_as_ubyte(noise[top:bot,lef:rig])\n",
    "    return (modded.reshape(dim,dim,1))\n",
    "\n",
    "#use DLIB to find facial landmarks, then apply occlusions\n",
    "#code shows test set occluded but can be modified to use train set\n",
    "dim = 48\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "W = np.squeeze(x_test_100, axis=3)\n",
    "for x in range(0,len(W),1): # change step here to reduce % of occlusions\n",
    "    gray = W[x].astype('uint8')\n",
    "    rects = detector(gray, 1)\n",
    "    features = {}\n",
    "    # For each detected face, find the landmark.\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        left_eye = shape[36] # position of left corner of left eye\n",
    "        right_eye = shape[42] # position of right corner of right eye\n",
    "        mouth = shape[48] # position of left corner of mouth\n",
    "        features = {\"mouth\": mouth, \"both\":left_eye}\n",
    "    gray = cv2.resize(gray, (dim,dim))\n",
    "    gray = np.array(gray)\n",
    "    gray = gray.reshape(dim, dim, 1)\n",
    "    img = noisy(\"s&p\",gray,features).astype('float32')\n",
    "    x_test[x] = img\n",
    "\n",
    "# apply z-score normalization after implementing occlusions\n",
    "# without taking the occlusions into consideration\n",
    "x_test -= test_mean\n",
    "x_test /= test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL AND TRAIN HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
