{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n",
      "instance length:  2304\n",
      "28709 train samples\n",
      "3589 test samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, ZeroPadding2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#------------------------------\n",
    "#cpu - gpu configuration\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) \n",
    "keras.backend.set_session(sess)\n",
    "#------------------------------\n",
    "#variables\n",
    "height = 48\n",
    "width = 48\n",
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "#------------------------------\n",
    "#read kaggle facial expression recognition challenge dataset (fer2013.csv)\n",
    "#https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "\n",
    "with open(\"../images/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n",
    "\n",
    "#------------------------------\n",
    "#initialize trainset and test set\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "#------------------------------\n",
    "#transfer train and test set data\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "        val = img.split(\" \")\n",
    "            \n",
    "        pixels = np.array(val, 'float32')\n",
    "        #pixels = cv2.resize(pixels,(width,height))\n",
    "        \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "    \n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\",end=\"\")\n",
    "\n",
    "#------------------------------\n",
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "x_train -= x_train_mean\n",
    "x_test -= x_test_mean\n",
    "x_train /= x_train_std \n",
    "x_test /= x_test_std\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], width, height, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], width, height, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 28679     \n",
      "=================================================================\n",
      "Total params: 33,624,775\n",
      "Trainable params: 33,624,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "448/448 [==============================] - 63s 140ms/step - loss: 1.8383 - acc: 0.2504 - val_loss: 1.8132 - val_acc: 0.2494\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24944, saving model to ../models/MODEL_VGG_f.h5\n",
      "Epoch 2/1000\n",
      "448/448 [==============================] - 58s 129ms/step - loss: 1.8129 - acc: 0.2513 - val_loss: 1.8119 - val_acc: 0.2482\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.24944\n",
      "Epoch 3/1000\n",
      "448/448 [==============================] - 57s 127ms/step - loss: 1.8121 - acc: 0.2518 - val_loss: 1.8166 - val_acc: 0.2491\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.24944\n",
      "Epoch 4/1000\n",
      "448/448 [==============================] - 58s 129ms/step - loss: 1.8119 - acc: 0.2509 - val_loss: 1.8129 - val_acc: 0.2502\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.24944 to 0.25021, saving model to ../models/MODEL_VGG_f.h5\n",
      "Epoch 5/1000\n",
      "448/448 [==============================] - 57s 127ms/step - loss: 1.8116 - acc: 0.2515 - val_loss: 1.8175 - val_acc: 0.2488\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.25021\n",
      "Epoch 6/1000\n",
      "448/448 [==============================] - 56s 126ms/step - loss: 1.8117 - acc: 0.2510 - val_loss: 1.8063 - val_acc: 0.2542\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.25021 to 0.25418, saving model to ../models/MODEL_VGG_f.h5\n",
      "Epoch 7/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8114 - acc: 0.2513 - val_loss: 1.8156 - val_acc: 0.2448\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.25418\n",
      "Epoch 8/1000\n",
      "448/448 [==============================] - 57s 127ms/step - loss: 1.8111 - acc: 0.2526 - val_loss: 1.8098 - val_acc: 0.2533\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.25418\n",
      "Epoch 9/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8121 - acc: 0.2503 - val_loss: 1.8137 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.25418\n",
      "Epoch 10/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8121 - acc: 0.2508 - val_loss: 1.8170 - val_acc: 0.2494\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.25418\n",
      "Epoch 11/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8107 - acc: 0.2516 - val_loss: 1.8030 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.25418\n",
      "Epoch 12/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8109 - acc: 0.2516 - val_loss: 1.8140 - val_acc: 0.2519\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.25418\n",
      "Epoch 13/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8105 - acc: 0.2517 - val_loss: 1.8152 - val_acc: 0.2468\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.25418\n",
      "Epoch 14/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8126 - acc: 0.2515 - val_loss: 1.8100 - val_acc: 0.2494\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.25418\n",
      "Epoch 15/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8110 - acc: 0.2505 - val_loss: 1.8139 - val_acc: 0.2525\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.25418\n",
      "Epoch 16/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8110 - acc: 0.2510 - val_loss: 1.8104 - val_acc: 0.2496\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.25418\n",
      "Epoch 17/1000\n",
      "448/448 [==============================] - 56s 125ms/step - loss: 1.8121 - acc: 0.2512 - val_loss: 1.8129 - val_acc: 0.2485\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.25418\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(width,height ,1), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "val_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "valid_generator = val_gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),#SGD(lr = 0.01, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.75, patience=3, verbose=1)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=11, verbose=1, mode='auto')\n",
    "\n",
    "checkpointer = ModelCheckpoint('../models/MODEL_VGG_f.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='../logs/VGG_f')\n",
    "\n",
    "steps_train = train_generator.n//train_generator.batch_size\n",
    "steps_valid = valid_generator.n//valid_generator.batch_size\n",
    "history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=steps_train, \n",
    "                                  validation_steps = steps_valid,\n",
    "                                  epochs=epochs, \n",
    "                                  validation_data=valid_generator,\n",
    "                                  callbacks=[early_stopper, checkpointer, tensorboard])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
